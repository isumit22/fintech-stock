{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a814acc9",
   "metadata": {},
   "source": [
    "# Stock Trend Prediction using Live WebSocket Data\n",
    "\n",
    "This notebook implements a real-time stock trend prediction system using live WebSocket feeds and online machine learning. The system predicts 5-minute price trends by processing streaming tick data and continuously updating an online classifier.\n",
    "\n",
    "## System Overview\n",
    "\n",
    "- **Data Source**: Live WebSocket feeds from stock data providers\n",
    "- **Aggregation**: Tick-to-minute OHLCV bars for stable features\n",
    "- **Features**: Technical indicators, momentum, volume analysis\n",
    "- **Model**: Online learning with River (AdaptiveRandomForest/LogisticRegression)\n",
    "- **Prediction Horizon**: 5-minute trend direction (up/neutral/down)\n",
    "- **Evaluation**: Real-time accuracy tracking and backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7602d",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Installation\n",
    "\n",
    "First, let's install and import all required libraries for our real-time stock trend prediction system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this once)\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✓ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    \"websockets\",\n",
    "    \"numpy\",\n",
    "    \"pandas\", \n",
    "    \"river\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"plotly\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    install_package(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cefcd9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgo\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msubplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_subplots\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import asyncio\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import deque\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Online machine learning\n",
    "from river import ensemble, linear_model, preprocessing, metrics\n",
    "\n",
    "# WebSocket and networking\n",
    "import websockets\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Standard library\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"River version: {river.__version__ if 'river' in globals() else 'Unknown'}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3687b5",
   "metadata": {},
   "source": [
    "## 2. WebSocket Connection Setup\n",
    "\n",
    "Configure websocket connection parameters for different stock data providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87b902b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mWebSocketConfig\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"Configuration for different WebSocket providers\"\"\"\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Provider configurations\u001b[39;49;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mWebSocketConfig\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m json.dumps({\n\u001b[32m     39\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: api_key\n\u001b[32m     41\u001b[39m         })\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_subscribe_message\u001b[39m(provider: \u001b[38;5;28mstr\u001b[39m, symbols: \u001b[43mList\u001b[49m[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[32m     46\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get subscription message for provider\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m provider == \u001b[33m\"\u001b[39m\u001b[33malpaca\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "class WebSocketConfig:\n",
    "    \"\"\"Configuration for different WebSocket providers\"\"\"\n",
    "    \n",
    "    # Provider configurations\n",
    "    PROVIDERS = {\n",
    "        \"alpaca\": {\n",
    "            \"url\": \"wss://stream.data.alpaca.markets/v2/iex\",\n",
    "            \"auth_required\": True,\n",
    "            \"subscribe_format\": \"trades\"\n",
    "        },\n",
    "        \"polygon\": {\n",
    "            \"url\": \"wss://socket.polygon.io/stocks\",\n",
    "            \"auth_required\": True,\n",
    "            \"subscribe_format\": \"T.*\"  # trades for all symbols\n",
    "        },\n",
    "        \"binance\": {\n",
    "            \"url\": \"wss://stream.binance.com:9443/ws/{symbol}@trade\",\n",
    "            \"auth_required\": False,\n",
    "            \"subscribe_format\": \"individual\"  # per symbol URL\n",
    "        },\n",
    "        \"iex\": {\n",
    "            \"url\": \"wss://cloud-sse.iexapis.com/stable/stocksUS\",\n",
    "            \"auth_required\": True,\n",
    "            \"subscribe_format\": \"symbols\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_auth_message(provider: str, api_key: str, secret_key: str = None):\n",
    "        \"\"\"Get authentication message for provider\"\"\"\n",
    "        if provider == \"alpaca\":\n",
    "            return json.dumps({\n",
    "                \"action\": \"auth\",\n",
    "                \"key\": api_key,\n",
    "                \"secret\": secret_key\n",
    "            })\n",
    "        elif provider == \"polygon\":\n",
    "            return json.dumps({\n",
    "                \"action\": \"auth\",\n",
    "                \"params\": api_key\n",
    "            })\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_subscribe_message(provider: str, symbols: List[str]):\n",
    "        \"\"\"Get subscription message for provider\"\"\"\n",
    "        if provider == \"alpaca\":\n",
    "            return json.dumps({\n",
    "                \"action\": \"subscribe\",\n",
    "                \"trades\": symbols\n",
    "            })\n",
    "        elif provider == \"polygon\":\n",
    "            return json.dumps({\n",
    "                \"action\": \"subscribe\",\n",
    "                \"params\": f\"T.{','.join(symbols)}\"\n",
    "            })\n",
    "        return None\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"SYMBOL\": \"AAPL\",\n",
    "    \"PROVIDER\": \"simulation\",  # Use simulation for demo\n",
    "    \"WEBSOCKET_URL\": \"wss://demo-websocket\",\n",
    "    \"API_KEY\": None,\n",
    "    \"SECRET_KEY\": None,\n",
    "    \n",
    "    # Prediction parameters\n",
    "    \"PRED_HORIZON_MINUTES\": 5,\n",
    "    \"FEATURE_WINDOW_MINUTES\": 15,\n",
    "    \"LABEL_THRESHOLD\": 0.001,  # 0.1% threshold\n",
    "    \n",
    "    # Model parameters\n",
    "    \"MODEL_TYPE\": \"random_forest\",  # or \"logistic\"\n",
    "    \"N_ESTIMATORS\": 10,\n",
    "    \n",
    "    # Data parameters\n",
    "    \"BAR_SECONDS\": 60,  # 1-minute bars\n",
    "    \"MAX_BARS\": 500,\n",
    "    \"MAX_PENDING\": 500\n",
    "}\n",
    "\n",
    "print(\"WebSocket configuration loaded!\")\n",
    "print(f\"Target symbol: {CONFIG['SYMBOL']}\")\n",
    "print(f\"Prediction horizon: {CONFIG['PRED_HORIZON_MINUTES']} minutes\")\n",
    "print(f\"Feature window: {CONFIG['FEATURE_WINDOW_MINUTES']} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ead67b",
   "metadata": {},
   "source": [
    "## 3. Real-time Data Ingestion and Parsing\n",
    "\n",
    "Implement message parsing functions to extract relevant data from WebSocket messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageParser:\n",
    "    \"\"\"Parse WebSocket messages from different providers\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_generic_message(msg_text: str) -> Optional[Dict]:\n",
    "        \"\"\"Parse generic trade message format\"\"\"\n",
    "        try:\n",
    "            data = json.loads(msg_text)\n",
    "        except Exception:\n",
    "            return None\n",
    "        \n",
    "        # Handle different message formats\n",
    "        symbol = data.get(\"symbol\") or data.get(\"s\") or data.get(\"sym\")\n",
    "        if not symbol:\n",
    "            return None\n",
    "            \n",
    "        price = data.get(\"price\") or data.get(\"p\")\n",
    "        size = data.get(\"size\") or data.get(\"v\") or data.get(\"volume\")\n",
    "        timestamp = data.get(\"t\") or data.get(\"timestamp\") or data.get(\"time\")\n",
    "        \n",
    "        if price is None:\n",
    "            return None\n",
    "            \n",
    "        # Parse timestamp\n",
    "        if timestamp is None:\n",
    "            dt = datetime.utcnow()\n",
    "        else:\n",
    "            try:\n",
    "                if isinstance(timestamp, str):\n",
    "                    dt = datetime.fromisoformat(timestamp.replace(\"Z\", \"+00:00\"))\n",
    "                else:\n",
    "                    # Assume epoch milliseconds\n",
    "                    dt = datetime.utcfromtimestamp(int(timestamp)/1000.0)\n",
    "            except Exception:\n",
    "                dt = datetime.utcnow()\n",
    "                \n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"price\": float(price),\n",
    "            \"size\": float(size) if size is not None else 0.0,\n",
    "            \"timestamp\": dt\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_alpaca_message(msg_text: str) -> Optional[Dict]:\n",
    "        \"\"\"Parse Alpaca-specific message format\"\"\"\n",
    "        try:\n",
    "            data = json.loads(msg_text)\n",
    "            if isinstance(data, list):\n",
    "                for msg in data:\n",
    "                    if msg.get(\"T\") == \"t\":  # trade message\n",
    "                        return {\n",
    "                            \"symbol\": msg.get(\"S\"),\n",
    "                            \"price\": float(msg.get(\"p\")),\n",
    "                            \"size\": float(msg.get(\"s\")),\n",
    "                            \"timestamp\": datetime.fromtimestamp(msg.get(\"t\") / 1e9)  # nanoseconds\n",
    "                        }\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_binance_message(msg_text: str) -> Optional[Dict]:\n",
    "        \"\"\"Parse Binance-specific message format\"\"\"\n",
    "        try:\n",
    "            data = json.loads(msg_text)\n",
    "            if data.get(\"e\") == \"trade\":\n",
    "                return {\n",
    "                    \"symbol\": data.get(\"s\"),\n",
    "                    \"price\": float(data.get(\"p\")),\n",
    "                    \"size\": float(data.get(\"q\")),\n",
    "                    \"timestamp\": datetime.fromtimestamp(int(data.get(\"T\")) / 1000)\n",
    "                }\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "# Mock data generator for testing\n",
    "class MockDataGenerator:\n",
    "    \"\"\"Generate realistic mock stock data for testing\"\"\"\n",
    "    \n",
    "    def __init__(self, symbol: str = \"AAPL\", initial_price: float = 150.0, volatility: float = 0.02):\n",
    "        self.symbol = symbol\n",
    "        self.current_price = initial_price\n",
    "        self.volatility = volatility\n",
    "        self.current_time = datetime.now()\n",
    "        \n",
    "    def generate_tick(self) -> Dict:\n",
    "        \"\"\"Generate a realistic stock tick\"\"\"\n",
    "        # Random walk with some mean reversion\n",
    "        change_pct = random.gauss(0, self.volatility / 100)\n",
    "        self.current_price *= (1 + change_pct)\n",
    "        \n",
    "        # Add some noise\n",
    "        self.current_price += random.gauss(0, 0.01)\n",
    "        \n",
    "        # Volume varies\n",
    "        volume = int(random.expovariate(1.0/100))\n",
    "        \n",
    "        tick = {\n",
    "            \"symbol\": self.symbol,\n",
    "            \"price\": round(self.current_price, 2),\n",
    "            \"size\": volume,\n",
    "            \"timestamp\": self.current_time\n",
    "        }\n",
    "        \n",
    "        # Advance time\n",
    "        self.current_time += timedelta(milliseconds=random.randint(100, 2000))\n",
    "        \n",
    "        return tick\n",
    "\n",
    "# Test the parser with mock data\n",
    "mock_generator = MockDataGenerator()\n",
    "test_tick = mock_generator.generate_tick()\n",
    "\n",
    "print(\"Mock tick generated:\")\n",
    "for key, value in test_tick.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "    \n",
    "# Test message parsing\n",
    "test_msg = json.dumps({\n",
    "    \"type\": \"trade\",\n",
    "    \"symbol\": \"AAPL\",\n",
    "    \"price\": 150.25,\n",
    "    \"size\": 100,\n",
    "    \"t\": \"2025-09-24T09:30:01.123Z\"\n",
    "})\n",
    "\n",
    "parsed = MessageParser.parse_generic_message(test_msg)\n",
    "print(\"\\nParsed message:\")\n",
    "for key, value in parsed.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e5e8a1",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Pipeline\n",
    "\n",
    "Create comprehensive feature engineering functions for technical analysis indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cabea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngine:\n",
    "    \"\"\"Compute streaming technical analysis features\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_features_from_bars(bars: List[Dict]) -> Dict:\n",
    "        \"\"\"Compute comprehensive technical features from OHLCV bars\"\"\"\n",
    "        if not bars:\n",
    "            return {}\n",
    "            \n",
    "        # Extract arrays\n",
    "        arr_close = np.array([b[\"close\"] for b in bars])\n",
    "        arr_open = np.array([b[\"open\"] for b in bars])\n",
    "        arr_high = np.array([b[\"high\"] for b in bars])\n",
    "        arr_low = np.array([b[\"low\"] for b in bars])\n",
    "        arr_volume = np.array([b[\"volume\"] for b in bars])\n",
    "        arr_vwap = np.array([b[\"vwap\"] for b in bars])\n",
    "        \n",
    "        n = len(arr_close)\n",
    "        last_price = float(arr_close[-1])\n",
    "        \n",
    "        features = {\n",
    "            \"n_bars\": n,\n",
    "            \"last_price\": last_price,\n",
    "        }\n",
    "        \n",
    "        # 1. Returns at multiple timeframes\n",
    "        for period, name in [(1, \"1m\"), (3, \"3m\"), (5, \"5m\"), (10, \"10m\")]:\n",
    "            if n >= period + 1:\n",
    "                features[f\"ret_{name}\"] = float((arr_close[-1] / arr_close[-period-1]) - 1.0)\n",
    "            else:\n",
    "                features[f\"ret_{name}\"] = 0.0\n",
    "        \n",
    "        # 2. Moving averages\n",
    "        for period in [3, 5, 10, 15]:\n",
    "            if n >= period:\n",
    "                features[f\"ma_{period}\"] = float(np.mean(arr_close[-period:]))\n",
    "                features[f\"ma_vol_{period}\"] = float(np.mean(arr_volume[-period:]))\n",
    "            else:\n",
    "                features[f\"ma_{period}\"] = last_price\n",
    "                features[f\"ma_vol_{period}\"] = float(np.mean(arr_volume))\n",
    "        \n",
    "        # 3. MA crossovers and gaps\n",
    "        if n >= 10:\n",
    "            features[\"ma_gap_3_10\"] = features[\"ma_3\"] - features[\"ma_10\"]\n",
    "            features[\"ma_gap_5_10\"] = features[\"ma_5\"] - features[\"ma_10\"]\n",
    "            features[\"price_vs_ma_10\"] = (last_price / features[\"ma_10\"]) - 1.0\n",
    "        \n",
    "        # 4. Volatility measures\n",
    "        for period in [3, 5, 10]:\n",
    "            if n >= period:\n",
    "                features[f\"std_{period}\"] = float(np.std(arr_close[-period:]))\n",
    "                features[f\"volatility_{period}\"] = features[f\"std_{period}\"] / last_price\n",
    "        \n",
    "        # 5. High-Low ranges\n",
    "        if n >= 1:\n",
    "            features[\"hl_range_1m\"] = float(arr_high[-1] - arr_low[-1])\n",
    "            features[\"hl_range_pct_1m\"] = features[\"hl_range_1m\"] / last_price\n",
    "        \n",
    "        if n >= 5:\n",
    "            recent_high = float(np.max(arr_high[-5:]))\n",
    "            recent_low = float(np.min(arr_low[-5:]))\n",
    "            features[\"hl_range_5m\"] = recent_high - recent_low\n",
    "            features[\"hl_range_pct_5m\"] = features[\"hl_range_5m\"] / last_price\n",
    "            \n",
    "            # Price position within recent range\n",
    "            if recent_high > recent_low:\n",
    "                features[\"price_position_5m\"] = (last_price - recent_low) / (recent_high - recent_low)\n",
    "            else:\n",
    "                features[\"price_position_5m\"] = 0.5\n",
    "        \n",
    "        # 6. Volume analysis\n",
    "        features[\"vol_last\"] = float(arr_volume[-1])\n",
    "        features[\"vol_avg_5m\"] = features.get(\"ma_vol_5\", features[\"vol_last\"])\n",
    "        features[\"vol_ratio\"] = features[\"vol_last\"] / (features[\"vol_avg_5m\"] + 1e-9)\n",
    "        \n",
    "        # Volume trend (slope)\n",
    "        if n >= 5:\n",
    "            vol_trend = np.polyfit(range(5), arr_volume[-5:], 1)[0]\n",
    "            features[\"vol_trend_5m\"] = float(vol_trend)\n",
    "        \n",
    "        # 7. VWAP analysis\n",
    "        features[\"vwap_last\"] = float(arr_vwap[-1])\n",
    "        features[\"vwap_gap\"] = features[\"vwap_last\"] - last_price\n",
    "        features[\"vwap_gap_pct\"] = features[\"vwap_gap\"] / last_price\n",
    "        \n",
    "        # 8. Momentum indicators\n",
    "        # Count consecutive up/down moves\n",
    "        ups = downs = 0\n",
    "        for i in range(1, min(n, 6)):\n",
    "            if arr_close[-i] > arr_close[-i-1]:\n",
    "                ups += 1\n",
    "            elif arr_close[-i] < arr_close[-i-1]:\n",
    "                downs += 1\n",
    "        \n",
    "        features[\"momentum_up_count\"] = ups\n",
    "        features[\"momentum_down_count\"] = downs\n",
    "        features[\"momentum_ratio\"] = ups / (ups + downs + 1e-9)\n",
    "        \n",
    "        # 9. RSI approximation\n",
    "        if n >= 14:\n",
    "            gains = np.maximum(np.diff(arr_close[-14:]), 0)\n",
    "            losses = np.maximum(-np.diff(arr_close[-14:]), 0)\n",
    "            avg_gain = np.mean(gains) if len(gains) > 0 else 0\n",
    "            avg_loss = np.mean(losses) if len(losses) > 0 else 0\n",
    "            \n",
    "            if avg_loss > 0:\n",
    "                rs = avg_gain / avg_loss\n",
    "                rsi = 100 - (100 / (1 + rs))\n",
    "                features[\"rsi_14\"] = float(rsi)\n",
    "            else:\n",
    "                features[\"rsi_14\"] = 50.0\n",
    "        else:\n",
    "            features[\"rsi_14\"] = 50.0\n",
    "        \n",
    "        # 10. Price acceleration\n",
    "        if n >= 3:\n",
    "            # Second derivative of price (acceleration)\n",
    "            prices_3 = arr_close[-3:]\n",
    "            vel_1 = prices_3[1] - prices_3[0]\n",
    "            vel_2 = prices_3[2] - prices_3[1]\n",
    "            acceleration = vel_2 - vel_1\n",
    "            features[\"price_acceleration\"] = float(acceleration / last_price)\n",
    "        \n",
    "        # 11. Bollinger Band position\n",
    "        if n >= 10:\n",
    "            bb_period = min(n, 20)\n",
    "            bb_ma = np.mean(arr_close[-bb_period:])\n",
    "            bb_std = np.std(arr_close[-bb_period:])\n",
    "            if bb_std > 0:\n",
    "                bb_upper = bb_ma + (2 * bb_std)\n",
    "                bb_lower = bb_ma - (2 * bb_std)\n",
    "                features[\"bb_position\"] = (last_price - bb_lower) / (bb_upper - bb_lower)\n",
    "            else:\n",
    "                features[\"bb_position\"] = 0.5\n",
    "        \n",
    "        return features\n",
    "\n",
    "# Test feature engineering\n",
    "test_bars = []\n",
    "base_price = 150.0\n",
    "base_volume = 1000\n",
    "\n",
    "for i in range(20):\n",
    "    price_change = random.gauss(0, 0.5)\n",
    "    price = base_price + price_change\n",
    "    volume = base_volume * random.uniform(0.5, 2.0)\n",
    "    \n",
    "    bar = {\n",
    "        \"timestamp\": datetime.now() - timedelta(minutes=20-i),\n",
    "        \"open\": price - random.uniform(-0.2, 0.2),\n",
    "        \"high\": price + random.uniform(0, 0.3),\n",
    "        \"low\": price - random.uniform(0, 0.3),\n",
    "        \"close\": price,\n",
    "        \"volume\": volume,\n",
    "        \"vwap\": price + random.uniform(-0.1, 0.1)\n",
    "    }\n",
    "    test_bars.append(bar)\n",
    "    base_price = price\n",
    "\n",
    "# Compute features\n",
    "test_features = FeatureEngine.compute_features_from_bars(test_bars)\n",
    "\n",
    "print(\"Sample features computed:\")\n",
    "for i, (key, value) in enumerate(test_features.items()):\n",
    "    print(f\"  {key}: {value:.6f}\")\n",
    "    if i >= 10:  # Show first 10 features\n",
    "        print(f\"  ... and {len(test_features) - 10} more features\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTotal features: {len(test_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60ff8a",
   "metadata": {},
   "source": [
    "## 5. Online Learning Model Implementation\n",
    "\n",
    "Set up River-based online machine learning models for real-time trend classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlinePredictor:\n",
    "    \"\"\"Online machine learning model for stock trend prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, model_type: str = \"random_forest\", **kwargs):\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        # Initialize model based on type\n",
    "        if model_type == \"random_forest\":\n",
    "            self.model = (\n",
    "                preprocessing.StandardScaler() | \n",
    "                ensemble.AdaptiveRandomForestClassifier(\n",
    "                    n_estimators=kwargs.get(\"n_estimators\", 10),\n",
    "                    seed=42\n",
    "                )\n",
    "            )\n",
    "        elif model_type == \"logistic\":\n",
    "            self.model = (\n",
    "                preprocessing.StandardScaler() |\n",
    "                linear_model.LogisticRegression()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        # Metrics\n",
    "        self.accuracy = metrics.Accuracy()\n",
    "        self.balanced_accuracy = metrics.BalancedAccuracy()\n",
    "        self.precision = metrics.MacroPrecision()\n",
    "        self.recall = metrics.MacroRecall()\n",
    "        self.confusion_matrix = metrics.ConfusionMatrix()\n",
    "        \n",
    "        # Tracking\n",
    "        self.predictions_made = 0\n",
    "        self.samples_learned = 0\n",
    "        \n",
    "    def predict(self, features: Dict) -> Tuple[str, Dict]:\n",
    "        \"\"\"Make a prediction and return probabilities\"\"\"\n",
    "        try:\n",
    "            prediction = self.model.predict_one(features)\n",
    "            probabilities = self.model.predict_proba_one(features)\n",
    "            self.predictions_made += 1\n",
    "            return prediction, probabilities\n",
    "        except Exception as e:\n",
    "            # Return neutral prediction if model fails\n",
    "            return \"neutral\", {\"up\": 0.33, \"neutral\": 0.34, \"down\": 0.33}\n",
    "    \n",
    "    def learn(self, features: Dict, label: str) -> None:\n",
    "        \"\"\"Update model with new labeled example\"\"\"\n",
    "        try:\n",
    "            # Get prediction before learning (for metrics)\n",
    "            pred_before_learn, _ = self.predict(features)\n",
    "            \n",
    "            # Learn from this example\n",
    "            self.model.learn_one(features, label)\n",
    "            self.samples_learned += 1\n",
    "            \n",
    "            # Update metrics\n",
    "            self.accuracy.update(label, pred_before_learn)\n",
    "            self.balanced_accuracy.update(label, pred_before_learn)\n",
    "            self.precision.update(label, pred_before_learn)\n",
    "            self.recall.update(label, pred_before_learn)\n",
    "            self.confusion_matrix.update(label, pred_before_learn)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Learning error: {e}\")\n",
    "    \n",
    "    def get_metrics(self) -> Dict:\n",
    "        \"\"\"Get current model performance metrics\"\"\"\n",
    "        try:\n",
    "            return {\n",
    "                \"accuracy\": self.accuracy.get(),\n",
    "                \"balanced_accuracy\": self.balanced_accuracy.get(),\n",
    "                \"precision\": self.precision.get(),\n",
    "                \"recall\": self.recall.get(),\n",
    "                \"predictions_made\": self.predictions_made,\n",
    "                \"samples_learned\": self.samples_learned,\n",
    "                \"confusion_matrix\": dict(self.confusion_matrix)\n",
    "            }\n",
    "        except:\n",
    "            return {\n",
    "                \"accuracy\": 0.0,\n",
    "                \"balanced_accuracy\": 0.0,\n",
    "                \"precision\": 0.0,\n",
    "                \"recall\": 0.0,\n",
    "                \"predictions_made\": self.predictions_made,\n",
    "                \"samples_learned\": self.samples_learned,\n",
    "                \"confusion_matrix\": {}\n",
    "            }\n",
    "\n",
    "# Labeling strategy\n",
    "class LabelStrategy:\n",
    "    \"\"\"Strategy for labeling price movements\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_label(current_price: float, future_price: float, \n",
    "                   threshold: float = 0.001) -> str:\n",
    "        \"\"\"\n",
    "        Create label based on future price movement\n",
    "        \n",
    "        Args:\n",
    "            current_price: Price at prediction time\n",
    "            future_price: Price after prediction horizon\n",
    "            threshold: Minimum movement to classify as up/down\n",
    "            \n",
    "        Returns:\n",
    "            \"up\", \"down\", or \"neutral\"\n",
    "        \"\"\"\n",
    "        return_pct = (future_price / current_price) - 1.0\n",
    "        \n",
    "        if return_pct > threshold:\n",
    "            return \"up\"\n",
    "        elif return_pct < -threshold:\n",
    "            return \"down\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "\n",
    "# Test the online predictor\n",
    "print(\"Testing Online Predictor...\")\n",
    "\n",
    "# Create predictor\n",
    "predictor = OnlinePredictor(model_type=\"random_forest\", n_estimators=5)\n",
    "\n",
    "# Generate some test data\n",
    "np.random.seed(42)\n",
    "for i in range(100):\n",
    "    # Create random features\n",
    "    test_features = {\n",
    "        \"ret_1m\": np.random.normal(0, 0.01),\n",
    "        \"ret_5m\": np.random.normal(0, 0.02),\n",
    "        \"ma_gap_3_10\": np.random.normal(0, 0.5),\n",
    "        \"vol_ratio\": np.random.lognormal(0, 0.3),\n",
    "        \"rsi_14\": np.random.uniform(20, 80)\n",
    "    }\n",
    "    \n",
    "    # Make prediction\n",
    "    pred, proba = predictor.predict(test_features)\n",
    "    \n",
    "    # Generate synthetic label (biased toward trend direction)\n",
    "    if test_features[\"ret_1m\"] > 0.005:\n",
    "        label = \"up\"\n",
    "    elif test_features[\"ret_1m\"] < -0.005:\n",
    "        label = \"down\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "    \n",
    "    # Learn from example\n",
    "    predictor.learn(test_features, label)\n",
    "\n",
    "# Check metrics\n",
    "metrics_result = predictor.get_metrics()\n",
    "print(\"\\\\nModel Performance after 100 samples:\")\n",
    "for key, value in metrics_result.items():\n",
    "    if key != \"confusion_matrix\":\n",
    "        print(f\"  {key}: {value:.4f}\" if isinstance(value, float) else f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\\\nModel type: {predictor.model_type}\")\n",
    "print(\"Online predictor ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d816a67",
   "metadata": {},
   "source": [
    "## 6. Data Aggregation and Bar Generation\n",
    "\n",
    "Implement tick-to-bar aggregation logic to create stable 1-minute OHLCV bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarAggregator:\n",
    "    \"\"\"Aggregate tick data into OHLCV bars\"\"\"\n",
    "    \n",
    "    def __init__(self, bar_duration_seconds: int = 60):\n",
    "        self.bar_duration = timedelta(seconds=bar_duration_seconds)\n",
    "        self.current_bar = None\n",
    "        self.completed_bars = deque(maxlen=500)\n",
    "        \n",
    "    def start_new_bar(self, tick: Dict) -> Dict:\n",
    "        \"\"\"Start a new bar with the first tick\"\"\"\n",
    "        bar_timestamp = self._align_timestamp(tick[\"timestamp\"])\n",
    "        \n",
    "        return {\n",
    "            \"timestamp\": bar_timestamp,\n",
    "            \"open\": tick[\"price\"],\n",
    "            \"high\": tick[\"price\"],\n",
    "            \"low\": tick[\"price\"],\n",
    "            \"close\": tick[\"price\"],\n",
    "            \"volume\": tick[\"size\"],\n",
    "            \"vwap_numerator\": tick[\"price\"] * tick[\"size\"],\n",
    "            \"vwap_denominator\": tick[\"size\"],\n",
    "            \"tick_count\": 1\n",
    "        }\n",
    "    \n",
    "    def update_bar(self, bar: Dict, tick: Dict) -> None:\n",
    "        \"\"\"Update existing bar with new tick\"\"\"\n",
    "        bar[\"high\"] = max(bar[\"high\"], tick[\"price\"])\n",
    "        bar[\"low\"] = min(bar[\"low\"], tick[\"price\"])\n",
    "        bar[\"close\"] = tick[\"price\"]\n",
    "        bar[\"volume\"] += tick[\"size\"]\n",
    "        bar[\"vwap_numerator\"] += tick[\"price\"] * tick[\"size\"]\n",
    "        bar[\"vwap_denominator\"] += tick[\"size\"]\n",
    "        bar[\"tick_count\"] += 1\n",
    "    \n",
    "    def finalize_bar(self, bar: Dict) -> Dict:\n",
    "        \"\"\"Finalize bar by computing derived fields\"\"\"\n",
    "        if bar[\"vwap_denominator\"] > 0:\n",
    "            vwap = bar[\"vwap_numerator\"] / bar[\"vwap_denominator\"]\n",
    "        else:\n",
    "            vwap = bar[\"close\"]\n",
    "        \n",
    "        return {\n",
    "            \"timestamp\": bar[\"timestamp\"],\n",
    "            \"open\": float(bar[\"open\"]),\n",
    "            \"high\": float(bar[\"high\"]),\n",
    "            \"low\": float(bar[\"low\"]),\n",
    "            \"close\": float(bar[\"close\"]),\n",
    "            \"volume\": float(bar[\"volume\"]),\n",
    "            \"vwap\": float(vwap),\n",
    "            \"tick_count\": bar[\"tick_count\"]\n",
    "        }\n",
    "    \n",
    "    def process_tick(self, tick: Dict) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Process a tick and return completed bar if any\n",
    "        \n",
    "        Returns:\n",
    "            Completed bar dict or None\n",
    "        \"\"\"\n",
    "        bar_timestamp = self._align_timestamp(tick[\"timestamp\"])\n",
    "        \n",
    "        # Check if we need to start a new bar\n",
    "        if (self.current_bar is None or \n",
    "            bar_timestamp != self.current_bar[\"timestamp\"]):\n",
    "            \n",
    "            # Finalize previous bar if exists\n",
    "            completed_bar = None\n",
    "            if self.current_bar is not None:\n",
    "                completed_bar = self.finalize_bar(self.current_bar)\n",
    "                self.completed_bars.append(completed_bar)\n",
    "            \n",
    "            # Start new bar\n",
    "            self.current_bar = self.start_new_bar(tick)\n",
    "            \n",
    "            return completed_bar\n",
    "        else:\n",
    "            # Update current bar\n",
    "            self.update_bar(self.current_bar, tick)\n",
    "            return None\n",
    "    \n",
    "    def _align_timestamp(self, timestamp: datetime) -> datetime:\n",
    "        \"\"\"Align timestamp to bar boundary (minute start)\"\"\"\n",
    "        return timestamp.replace(second=0, microsecond=0)\n",
    "    \n",
    "    def get_recent_bars(self, n: int = None) -> List[Dict]:\n",
    "        \"\"\"Get recent completed bars\"\"\"\n",
    "        if n is None:\n",
    "            return list(self.completed_bars)\n",
    "        else:\n",
    "            return list(self.completed_bars)[-n:] if len(self.completed_bars) >= n else list(self.completed_bars)\n",
    "    \n",
    "    def get_current_bar_simulation(self) -> Optional[Dict]:\n",
    "        \"\"\"Get current bar as if it were finalized (for feature computation)\"\"\"\n",
    "        if self.current_bar is None:\n",
    "            return None\n",
    "        return self.finalize_bar(self.current_bar)\n",
    "\n",
    "# Test bar aggregation\n",
    "print(\"Testing Bar Aggregation...\")\n",
    "\n",
    "# Create aggregator\n",
    "aggregator = BarAggregator(bar_duration_seconds=60)  # 1-minute bars\n",
    "\n",
    "# Generate test ticks\n",
    "mock_gen = MockDataGenerator(\"AAPL\", 150.0)\n",
    "completed_bars = []\n",
    "\n",
    "print(\"Processing ticks...\")\n",
    "for i in range(200):  # Process 200 ticks\n",
    "    tick = mock_gen.generate_tick()\n",
    "    \n",
    "    # Process tick\n",
    "    completed_bar = aggregator.process_tick(tick)\n",
    "    \n",
    "    if completed_bar:\n",
    "        completed_bars.append(completed_bar)\n",
    "        print(f\"Bar {len(completed_bars)}: {completed_bar['timestamp'].strftime('%H:%M')} \"\n",
    "              f\"O:{completed_bar['open']:.2f} H:{completed_bar['high']:.2f} \"\n",
    "              f\"L:{completed_bar['low']:.2f} C:{completed_bar['close']:.2f} \"\n",
    "              f\"V:{completed_bar['volume']:.0f} Ticks:{completed_bar['tick_count']}\")\n",
    "\n",
    "print(f\"\\\\nGenerated {len(completed_bars)} completed bars\")\n",
    "print(f\"Current bar in progress: {aggregator.current_bar is not None}\")\n",
    "\n",
    "# Get recent bars\n",
    "recent_bars = aggregator.get_recent_bars(5)\n",
    "print(f\"Recent {len(recent_bars)} bars available for features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71979b3d",
   "metadata": {},
   "source": [
    "## 7. Labeling Strategy for 5-minute Predictions\n",
    "\n",
    "Develop the labeling methodology for 5-minute trend classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a36ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionSnapshot:\n",
    "    \"\"\"Manages prediction snapshots and labeling\"\"\"\n",
    "    \n",
    "    def __init__(self, prediction_horizon: timedelta, label_threshold: float = 0.001):\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        self.label_threshold = label_threshold\n",
    "        self.pending_snapshots = deque()\n",
    "        \n",
    "    def create_snapshot(self, timestamp: datetime, price: float, features: Dict) -> Dict:\n",
    "        \"\"\"Create a prediction snapshot\"\"\"\n",
    "        snapshot = {\n",
    "            \"created_at\": timestamp,\n",
    "            \"price_at_creation\": price,\n",
    "            \"features_at_creation\": features.copy(),\n",
    "            \"target_time\": timestamp + self.prediction_horizon,\n",
    "            \"is_labeled\": False,\n",
    "            \"label\": None,\n",
    "            \"future_price\": None\n",
    "        }\n",
    "        \n",
    "        self.pending_snapshots.append(snapshot)\n",
    "        return snapshot\n",
    "    \n",
    "    def check_for_labeling(self, current_time: datetime, current_price: float) -> List[Dict]:\n",
    "        \"\"\"Check if any snapshots can be labeled now\"\"\"\n",
    "        labeled_snapshots = []\n",
    "        \n",
    "        while (self.pending_snapshots and \n",
    "               self.pending_snapshots[0][\"target_time\"] <= current_time):\n",
    "            \n",
    "            snapshot = self.pending_snapshots.popleft()\n",
    "            \n",
    "            # Label the snapshot\n",
    "            snapshot[\"future_price\"] = current_price\n",
    "            snapshot[\"label\"] = LabelStrategy.make_label(\n",
    "                snapshot[\"price_at_creation\"], \n",
    "                current_price,\n",
    "                self.label_threshold\n",
    "            )\n",
    "            snapshot[\"is_labeled\"] = True\n",
    "            snapshot[\"labeled_at\"] = current_time\n",
    "            \n",
    "            labeled_snapshots.append(snapshot)\n",
    "        \n",
    "        return labeled_snapshots\n",
    "    \n",
    "    def get_pending_count(self) -> int:\n",
    "        \"\"\"Get number of pending snapshots\"\"\"\n",
    "        return len(self.pending_snapshots)\n",
    "    \n",
    "    def cleanup_old_snapshots(self, max_age: timedelta = timedelta(hours=1)):\n",
    "        \"\"\"Remove very old pending snapshots\"\"\"\n",
    "        cutoff_time = datetime.now() - max_age\n",
    "        while (self.pending_snapshots and \n",
    "               self.pending_snapshots[0][\"created_at\"] < cutoff_time):\n",
    "            self.pending_snapshots.popleft()\n",
    "\n",
    "# Advanced labeling strategies\n",
    "class AdvancedLabelStrategy:\n",
    "    \"\"\"Advanced labeling strategies beyond simple threshold\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def adaptive_threshold_label(current_price: float, future_price: float, \n",
    "                               volatility: float, base_threshold: float = 0.001) -> str:\n",
    "        \"\"\"Adaptive threshold based on current volatility\"\"\"\n",
    "        # Adjust threshold based on volatility\n",
    "        adjusted_threshold = base_threshold * max(1.0, volatility * 100)\n",
    "        return LabelStrategy.make_label(current_price, future_price, adjusted_threshold)\n",
    "    \n",
    "    @staticmethod\n",
    "    def momentum_weighted_label(current_price: float, future_price: float,\n",
    "                              recent_momentum: float, threshold: float = 0.001) -> str:\n",
    "        \"\"\"Weight the label based on recent momentum\"\"\"\n",
    "        return_pct = (future_price / current_price) - 1.0\n",
    "        \n",
    "        # Adjust return based on momentum continuation\n",
    "        momentum_factor = 1.0 + (recent_momentum * 0.5)  # Momentum boost\n",
    "        adjusted_return = return_pct * momentum_factor\n",
    "        \n",
    "        if adjusted_return > threshold:\n",
    "            return \"up\"\n",
    "        elif adjusted_return < -threshold:\n",
    "            return \"down\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def multi_horizon_label(prices: List[float], horizons: List[int],\n",
    "                          threshold: float = 0.001) -> str:\n",
    "        \"\"\"Label based on multiple future horizons\"\"\"\n",
    "        if len(prices) < max(horizons) + 1:\n",
    "            return \"neutral\"\n",
    "            \n",
    "        current_price = prices[0]\n",
    "        votes = {\"up\": 0, \"down\": 0, \"neutral\": 0}\n",
    "        \n",
    "        for horizon in horizons:\n",
    "            if horizon < len(prices):\n",
    "                future_price = prices[horizon]\n",
    "                label = LabelStrategy.make_label(current_price, future_price, threshold)\n",
    "                votes[label] += 1\n",
    "        \n",
    "        # Return majority vote\n",
    "        return max(votes.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "# Test labeling system\n",
    "print(\"Testing Prediction Snapshot System...\")\n",
    "\n",
    "# Create snapshot manager\n",
    "snapshot_manager = PredictionSnapshot(\n",
    "    prediction_horizon=timedelta(minutes=5),\n",
    "    label_threshold=0.001\n",
    ")\n",
    "\n",
    "# Simulate creating and labeling snapshots\n",
    "base_time = datetime.now()\n",
    "base_price = 150.0\n",
    "\n",
    "print(\"Creating snapshots...\")\n",
    "for i in range(10):\n",
    "    timestamp = base_time + timedelta(minutes=i)\n",
    "    price = base_price + random.gauss(0, 1.0)\n",
    "    features = {\"ret_1m\": random.gauss(0, 0.01), \"vol_ratio\": random.uniform(0.5, 2.0)}\n",
    "    \n",
    "    snapshot = snapshot_manager.create_snapshot(timestamp, price, features)\n",
    "    print(f\"Snapshot {i+1}: {timestamp.strftime('%H:%M')} price={price:.2f} \"\n",
    "          f\"target_time={snapshot['target_time'].strftime('%H:%M')}\")\n",
    "\n",
    "print(f\"\\\\nPending snapshots: {snapshot_manager.get_pending_count()}\")\n",
    "\n",
    "# Simulate time passing and labeling\n",
    "print(\"\\\\nSimulating time passage and labeling...\")\n",
    "for i in range(15):\n",
    "    current_time = base_time + timedelta(minutes=10 + i)\n",
    "    current_price = base_price + random.gauss(0, 2.0)\n",
    "    \n",
    "    labeled = snapshot_manager.check_for_labeling(current_time, current_price)\n",
    "    \n",
    "    for snapshot in labeled:\n",
    "        return_pct = (snapshot[\"future_price\"] / snapshot[\"price_at_creation\"] - 1) * 100\n",
    "        print(f\"Labeled snapshot: created {snapshot['created_at'].strftime('%H:%M')} \"\n",
    "              f\"price {snapshot['price_at_creation']:.2f} -> {snapshot['future_price']:.2f} \"\n",
    "              f\"({return_pct:+.2f}%) = {snapshot['label']}\")\n",
    "\n",
    "print(f\"\\\\nRemaining pending snapshots: {snapshot_manager.get_pending_count()}\")\n",
    "\n",
    "# Test advanced labeling\n",
    "print(\"\\\\nTesting advanced labeling strategies...\")\n",
    "test_prices = [100.0, 100.5, 101.2, 100.8, 101.5]  # 5 time points\n",
    "volatility = 0.02\n",
    "momentum = 0.01\n",
    "\n",
    "for i in range(len(test_prices) - 1):\n",
    "    current = test_prices[i]\n",
    "    future = test_prices[i + 1]\n",
    "    \n",
    "    basic_label = LabelStrategy.make_label(current, future, 0.001)\n",
    "    adaptive_label = AdvancedLabelStrategy.adaptive_threshold_label(current, future, volatility)\n",
    "    momentum_label = AdvancedLabelStrategy.momentum_weighted_label(current, future, momentum)\n",
    "    \n",
    "    print(f\"Price {current:.2f} -> {future:.2f}: basic={basic_label}, \"\n",
    "          f\"adaptive={adaptive_label}, momentum={momentum_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f57060",
   "metadata": {},
   "source": [
    "## 8. Model Training and Prediction Loop\n",
    "\n",
    "Implement the main event loop that processes streaming data and updates the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e82175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrendPredictionSystem:\n",
    "    \"\"\"Complete trend prediction system\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        \n",
    "        # Components\n",
    "        self.bar_aggregator = BarAggregator(config[\"BAR_SECONDS\"])\n",
    "        self.predictor = OnlinePredictor(\n",
    "            model_type=config[\"MODEL_TYPE\"],\n",
    "            n_estimators=config.get(\"N_ESTIMATORS\", 10)\n",
    "        )\n",
    "        self.snapshot_manager = PredictionSnapshot(\n",
    "            prediction_horizon=timedelta(minutes=config[\"PRED_HORIZON_MINUTES\"]),\n",
    "            label_threshold=config[\"LABEL_THRESHOLD\"]\n",
    "        )\n",
    "        self.feature_engine = FeatureEngine()\n",
    "        self.message_parser = MessageParser()\n",
    "        \n",
    "        # Statistics\n",
    "        self.ticks_processed = 0\n",
    "        self.predictions_made = 0\n",
    "        self.labels_created = 0\n",
    "        self.start_time = datetime.now()\n",
    "        \n",
    "        # Storage for analysis\n",
    "        self.prediction_history = []\n",
    "        self.performance_history = []\n",
    "        \n",
    "    async def process_tick(self, tick_data: Dict) -> None:\n",
    "        \"\"\"Process a single tick through the entire pipeline\"\"\"\n",
    "        self.ticks_processed += 1\n",
    "        \n",
    "        # 1. Aggregate tick into bars\n",
    "        completed_bar = self.bar_aggregator.process_tick(tick_data)\n",
    "        \n",
    "        # 2. If we have a new completed bar, check for labeling\n",
    "        if completed_bar:\n",
    "            await self._handle_new_bar(completed_bar)\n",
    "        \n",
    "        # 3. Generate features and make prediction\n",
    "        await self._make_prediction(tick_data)\n",
    "        \n",
    "        # 4. Log progress periodically\n",
    "        if self.ticks_processed % 100 == 0:\n",
    "            await self._log_progress()\n",
    "    \n",
    "    async def _handle_new_bar(self, completed_bar: Dict) -> None:\n",
    "        \"\"\"Handle a newly completed bar\"\"\"\n",
    "        # Check for snapshots that can be labeled\n",
    "        current_time = completed_bar[\"timestamp\"]\n",
    "        current_price = completed_bar[\"close\"]\n",
    "        \n",
    "        labeled_snapshots = self.snapshot_manager.check_for_labeling(current_time, current_price)\n",
    "        \n",
    "        # Train model on labeled examples\n",
    "        for snapshot in labeled_snapshots:\n",
    "            self.predictor.learn(snapshot[\"features_at_creation\"], snapshot[\"label\"])\n",
    "            self.labels_created += 1\n",
    "            \n",
    "            # Log training example\n",
    "            return_pct = (snapshot[\"future_price\"] / snapshot[\"price_at_creation\"] - 1) * 100\n",
    "            print(f\"[LEARN] {snapshot['created_at'].strftime('%H:%M:%S')} \"\n",
    "                  f\"→ {snapshot['label']} ({return_pct:+.2f}%)\")\n",
    "    \n",
    "    async def _make_prediction(self, tick_data: Dict) -> None:\n",
    "        \\\"\\\"\\\"Generate features and make prediction\\\"\\\"\\\"\n",
    "        # Get recent bars for feature computation\n",
    "        recent_bars = self.bar_aggregator.get_recent_bars(self.config[\"FEATURE_WINDOW_MINUTES\"])\n",
    "        \n",
    "        # Add current bar simulation if available\n",
    "        current_bar_sim = self.bar_aggregator.get_current_bar_simulation()\n",
    "        if current_bar_sim:\n",
    "            recent_bars.append(current_bar_sim)\n",
    "        \n",
    "        # Keep only the required window\n",
    "        if len(recent_bars) > self.config[\"FEATURE_WINDOW_MINUTES\"]:\n",
    "            recent_bars = recent_bars[-self.config[\"FEATURE_WINDOW_MINUTES\"]:]\n",
    "        \n",
    "        # Compute features\n",
    "        features = self.feature_engine.compute_features_from_bars(recent_bars)\n",
    "        \n",
    "        if not features:  # Not enough data yet\n",
    "            return\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction, probabilities = self.predictor.predict(features)\n",
    "        self.predictions_made += 1\n",
    "        \n",
    "        # Create snapshot for future labeling\n",
    "        snapshot = self.snapshot_manager.create_snapshot(\n",
    "            tick_data[\"timestamp\"],\n",
    "            tick_data[\"price\"],\n",
    "            features\n",
    "        )\n",
    "        \n",
    "        # Store prediction for analysis\n",
    "        prediction_record = {\n",
    "            \"timestamp\": tick_data[\"timestamp\"],\n",
    "            \"price\": tick_data[\"price\"],\n",
    "            \"prediction\": prediction,\n",
    "            \"probabilities\": probabilities,\n",
    "            \"features\": features,\n",
    "            \"snapshot_id\": id(snapshot)\n",
    "        }\n",
    "        self.prediction_history.append(prediction_record)\n",
    "        \n",
    "        # Keep history bounded\n",
    "        if len(self.prediction_history) > 1000:\n",
    "            self.prediction_history = self.prediction_history[-1000:]\n",
    "        \n",
    "        # Log prediction\n",
    "        prob_str = f\"({probabilities.get('up', 0):.2f}/{probabilities.get('neutral', 0):.2f}/{probabilities.get('down', 0):.2f})\"\n",
    "        print(f\"[PRED] {tick_data['timestamp'].strftime('%H:%M:%S')} \"\n",
    "              f\"${tick_data['price']:.2f} → {prediction} {prob_str}\")\n",
    "    \n",
    "    async def _log_progress(self) -> None:\n",
    "        \\\"\\\"\\\"Log system progress and performance\\\"\\\"\\\"\n",
    "        metrics = self.predictor.get_metrics()\n",
    "        runtime = datetime.now() - self.start_time\n",
    "        \n",
    "        # Store performance snapshot\n",
    "        perf_snapshot = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"ticks_processed\": self.ticks_processed,\n",
    "            \"predictions_made\": self.predictions_made,\n",
    "            \"labels_created\": self.labels_created,\n",
    "            \"pending_snapshots\": self.snapshot_manager.get_pending_count(),\n",
    "            \"runtime_minutes\": runtime.total_seconds() / 60,\n",
    "            **metrics\n",
    "        }\n",
    "        self.performance_history.append(perf_snapshot)\n",
    "        \n",
    "        print(f\"\\\\n=== PROGRESS UPDATE ===\")\n",
    "        print(f\"Runtime: {runtime}\")\n",
    "        print(f\"Ticks: {self.ticks_processed}, Predictions: {self.predictions_made}, Labels: {self.labels_created}\")\n",
    "        print(f\"Accuracy: {metrics.get('accuracy', 0):.4f}, Pending: {self.snapshot_manager.get_pending_count()}\")\n",
    "        print(f\"Recent bars: {len(self.bar_aggregator.get_recent_bars())}\")\n",
    "        print(\"=\" * 25)\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \\\"\\\"\\\"Get comprehensive system statistics\\\"\\\"\\\"\n",
    "        metrics = self.predictor.get_metrics()\n",
    "        runtime = datetime.now() - self.start_time\n",
    "        \n",
    "        return {\n",
    "            \"runtime_seconds\": runtime.total_seconds(),\n",
    "            \"ticks_processed\": self.ticks_processed,\n",
    "            \"predictions_made\": self.predictions_made,\n",
    "            \"labels_created\": self.labels_created,\n",
    "            \"pending_snapshots\": self.snapshot_manager.get_pending_count(),\n",
    "            \"completed_bars\": len(self.bar_aggregator.get_recent_bars()),\n",
    "            \"prediction_history_length\": len(self.prediction_history),\n",
    "            \"performance_snapshots\": len(self.performance_history),\n",
    "            **metrics\n",
    "        }\n",
    "\n",
    "# Test the complete system with mock data\n",
    "async def test_prediction_system():\n",
    "    \\\"\\\"\\\"Test the complete prediction system\\\"\\\"\\\"\n",
    "    print(\"=== TESTING COMPLETE PREDICTION SYSTEM ===\")\n",
    "    \n",
    "    # Create system\n",
    "    system = TrendPredictionSystem(CONFIG)\n",
    "    \n",
    "    # Generate mock data\n",
    "    mock_gen = MockDataGenerator(\"AAPL\", 150.0, volatility=0.02)\n",
    "    \n",
    "    print(\"Processing ticks...\")\n",
    "    for i in range(300):  # Process 300 ticks\n",
    "        tick = mock_gen.generate_tick()\n",
    "        await system.process_tick(tick)\n",
    "        \n",
    "        # Small delay to simulate real-time\n",
    "        await asyncio.sleep(0.01)\n",
    "    \n",
    "    # Get final statistics\n",
    "    stats = system.get_stats()\n",
    "    print(\"\\\\n=== FINAL STATISTICS ===\")\n",
    "    for key, value in stats.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    return system\n",
    "\n",
    "# Run the test\n",
    "print(\"Starting prediction system test...\")\n",
    "system = await test_prediction_system()\n",
    "print(\"\\\\nTest completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00456edb",
   "metadata": {},
   "source": [
    "## 9. Performance Metrics and Monitoring\n",
    "\n",
    "Track model performance and visualize key metrics in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance visualization and monitoring\n",
    "def plot_system_performance(system: TrendPredictionSystem):\n",
    "    \\\"\\\"\\\"Create comprehensive performance visualizations\\\"\\\"\\\"\n",
    "    \n",
    "    # Extract performance history\n",
    "    if not system.performance_history:\n",
    "        print(\"No performance history available\")\n",
    "        return\n",
    "    \n",
    "    perf_df = pd.DataFrame(system.performance_history)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=['Model Accuracy Over Time', 'Predictions vs Labels', \n",
    "                       'Confusion Matrix Heatmap', 'Processing Statistics'],\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Accuracy over time\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=perf_df['timestamp'], y=perf_df['accuracy'], \n",
    "                  mode='lines+markers', name='Accuracy', line=dict(color='green')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    if 'balanced_accuracy' in perf_df.columns:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=perf_df['timestamp'], y=perf_df['balanced_accuracy'], \n",
    "                      mode='lines+markers', name='Balanced Accuracy', line=dict(color='blue')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. Predictions vs Labels created\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=perf_df['timestamp'], y=perf_df['predictions_made'], \n",
    "                  mode='lines', name='Predictions', line=dict(color='orange')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=perf_df['timestamp'], y=perf_df['labels_created'], \n",
    "                  mode='lines', name='Labels Created', line=dict(color='red')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Processing rate\n",
    "    if len(perf_df) > 1:\n",
    "        processing_rate = perf_df['ticks_processed'].diff() / perf_df['runtime_minutes'].diff()\n",
    "        processing_rate = processing_rate.fillna(0)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=perf_df['timestamp'], y=processing_rate, \n",
    "                      mode='lines', name='Ticks/Min', line=dict(color='purple')),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. Pending snapshots\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=perf_df['timestamp'], y=perf_df['pending_snapshots'], \n",
    "                  mode='lines', name='Pending', line=dict(color='brown')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Stock Trend Prediction System - Performance Dashboard\",\n",
    "        showlegend=True,\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def plot_prediction_analysis(system: TrendPredictionSystem):\n",
    "    \\\"\\\"\\\"Analyze prediction patterns and confidence\\\"\\\"\\\"\n",
    "    \n",
    "    if not system.prediction_history:\n",
    "        print(\"No prediction history available\")\n",
    "        return\n",
    "    \n",
    "    pred_df = pd.DataFrame(system.prediction_history)\n",
    "    \n",
    "    # Extract probability scores\n",
    "    pred_df['prob_up'] = pred_df['probabilities'].apply(lambda x: x.get('up', 0))\n",
    "    pred_df['prob_down'] = pred_df['probabilities'].apply(lambda x: x.get('down', 0))\n",
    "    pred_df['prob_neutral'] = pred_df['probabilities'].apply(lambda x: x.get('neutral', 0))\n",
    "    pred_df['max_prob'] = pred_df[['prob_up', 'prob_down', 'prob_neutral']].max(axis=1)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=['Prediction Distribution', 'Confidence Over Time', \n",
    "                       'Price vs Predictions', 'Feature Correlation'],\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": True}],\n",
    "               [{\"secondary_y\": True}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Prediction distribution\n",
    "    pred_counts = pred_df['prediction'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=pred_counts.index, y=pred_counts.values, \n",
    "               marker_color=['green', 'gray', 'red']),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Confidence over time\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=pred_df['timestamp'], y=pred_df['max_prob'], \n",
    "                  mode='lines', name='Max Probability', line=dict(color='blue')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Price on secondary y-axis\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=pred_df['timestamp'], y=pred_df['price'], \n",
    "                  mode='lines', name='Price', line=dict(color='black', width=1)),\n",
    "        row=1, col=2, secondary_y=True\n",
    "    )\n",
    "    \n",
    "    # 3. Price movement with predictions\n",
    "    # Color code predictions\n",
    "    colors = {'up': 'green', 'down': 'red', 'neutral': 'gray'}\n",
    "    for pred_type in ['up', 'down', 'neutral']:\n",
    "        mask = pred_df['prediction'] == pred_type\n",
    "        if mask.any():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=pred_df[mask]['timestamp'], y=pred_df[mask]['price'], \n",
    "                          mode='markers', name=f'Pred: {pred_type}',\n",
    "                          marker=dict(color=colors[pred_type], size=4)),\n",
    "                row=2, col=1\n",
    "            )\n",
    "    \n",
    "    # 4. Feature importance (if we can extract it)\n",
    "    # Show distribution of key features\n",
    "    if len(system.prediction_history) > 10:\n",
    "        # Extract a key feature for analysis\n",
    "        try:\n",
    "            ret_1m_values = [pred['features'].get('ret_1m', 0) for pred in system.prediction_history[-50:]]\n",
    "            vol_ratio_values = [pred['features'].get('vol_ratio', 0) for pred in system.prediction_history[-50:]]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Histogram(x=ret_1m_values, name='Return 1m Distribution', \n",
    "                           opacity=0.7, marker_color='blue'),\n",
    "                row=2, col=2\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Prediction Analysis Dashboard\",\n",
    "        showlegend=True,\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    # Update y-axis labels\n",
    "    fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Probability\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Price ($)\", row=1, col=2, secondary_y=True)\n",
    "    fig.update_yaxes(title_text=\"Price ($)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def generate_performance_report(system: TrendPredictionSystem) -> str:\n",
    "    \\\"\\\"\\\"Generate a comprehensive performance report\\\"\\\"\\\"\n",
    "    \n",
    "    stats = system.get_stats()\n",
    "    metrics = system.predictor.get_metrics()\n",
    "    \n",
    "    report = f\\\"\\\"\\\"\n",
    "# Stock Trend Prediction System - Performance Report\n",
    "\n",
    "## System Statistics\n",
    "- **Runtime**: {stats['runtime_seconds']:.1f} seconds\n",
    "- **Ticks Processed**: {stats['ticks_processed']:,}\n",
    "- **Predictions Made**: {stats['predictions_made']:,}\n",
    "- **Labels Created**: {stats['labels_created']:,}\n",
    "- **Processing Rate**: {stats['ticks_processed'] / max(stats['runtime_seconds'], 1):.1f} ticks/second\n",
    "\n",
    "## Model Performance\n",
    "- **Accuracy**: {metrics.get('accuracy', 0):.4f}\n",
    "- **Balanced Accuracy**: {metrics.get('balanced_accuracy', 0):.4f}\n",
    "- **Precision**: {metrics.get('precision', 0):.4f}\n",
    "- **Recall**: {metrics.get('recall', 0):.4f}\n",
    "\n",
    "## Data Pipeline Status\n",
    "- **Completed Bars**: {stats['completed_bars']}\n",
    "- **Pending Snapshots**: {stats['pending_snapshots']}\n",
    "- **Prediction History**: {stats['prediction_history_length']} records\n",
    "\n",
    "## Model Configuration\n",
    "- **Model Type**: {system.config['MODEL_TYPE']}\n",
    "- **Prediction Horizon**: {system.config['PRED_HORIZON_MINUTES']} minutes\n",
    "- **Feature Window**: {system.config['FEATURE_WINDOW_MINUTES']} minutes\n",
    "- **Label Threshold**: {system.config['LABEL_THRESHOLD']:.4f}\n",
    "\n",
    "## Recent Predictions\n",
    "\\\"\\\"\\\"\n",
    "    \n",
    "    # Add recent predictions\n",
    "    if system.prediction_history:\n",
    "        recent_preds = system.prediction_history[-5:]\n",
    "        for pred in recent_preds:\n",
    "            timestamp = pred['timestamp'].strftime('%H:%M:%S')\n",
    "            price = pred['price']\n",
    "            prediction = pred['prediction']\n",
    "            max_prob = max(pred['probabilities'].values())\n",
    "            report += f\\\"- {timestamp}: ${price:.2f} → {prediction} ({max_prob:.2f})\\\\n\\\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Test performance monitoring with our system\n",
    "if 'system' in locals():\n",
    "    print(\"Generating performance visualizations...\")\n",
    "    \n",
    "    # Performance dashboard\n",
    "    plot_system_performance(system)\n",
    "    \n",
    "    # Prediction analysis\n",
    "    plot_prediction_analysis(system)\n",
    "    \n",
    "    # Generate report\n",
    "    report = generate_performance_report(system)\n",
    "    print(report)\n",
    "else:\n",
    "    print(\"Run the prediction system test first to generate performance data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a23a90",
   "metadata": {},
   "source": [
    "## 10. Backtesting Framework\n",
    "\n",
    "Create a backtesting system to evaluate prediction accuracy with historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtester:\n",
    "    \"\"\"Backtesting framework for strategy evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_capital: float = 10000, transaction_cost: float = 0.001):\n",
    "        self.initial_capital = initial_capital\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.capital = self.initial_capital\n",
    "        self.position = 0  # 0=neutral, 1=long, -1=short\n",
    "        self.trades = []\n",
    "        self.portfolio_values = []\n",
    "        self.entry_price = 0\n",
    "        \n",
    "    def execute_signal(self, timestamp, price, signal, confidence=1.0):\n",
    "        \"\"\"Execute trading signal\"\"\"\n",
    "        trade_size = confidence * 0.1  # Risk 10% per trade\n",
    "        \n",
    "        if signal == \"up\" and self.position <= 0:\n",
    "            # Go long\n",
    "            if self.position == -1:  # Close short first\n",
    "                pnl = (self.entry_price - price) * abs(self.position)\n",
    "                self.capital += pnl * self.capital * 0.1\n",
    "            \n",
    "            self.position = 1\n",
    "            self.entry_price = price\n",
    "            cost = self.capital * trade_size * self.transaction_cost\n",
    "            self.capital -= cost\n",
    "            \n",
    "        elif signal == \"down\" and self.position >= 0:\n",
    "            # Go short\n",
    "            if self.position == 1:  # Close long first\n",
    "                pnl = (price - self.entry_price) * abs(self.position)\n",
    "                self.capital += pnl * self.capital * 0.1\n",
    "            \n",
    "            self.position = -1\n",
    "            self.entry_price = price\n",
    "            cost = self.capital * trade_size * self.transaction_cost\n",
    "            self.capital -= cost\n",
    "            \n",
    "        # Record trade\n",
    "        self.trades.append({\n",
    "            \"timestamp\": timestamp,\n",
    "            \"price\": price,\n",
    "            \"signal\": signal,\n",
    "            \"position\": self.position,\n",
    "            \"capital\": self.capital\n",
    "        })\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        if self.position != 0:\n",
    "            unrealized_pnl = (price - self.entry_price) * self.position * self.capital * 0.1\n",
    "            portfolio_value = self.capital + unrealized_pnl\n",
    "        else:\n",
    "            portfolio_value = self.capital\n",
    "            \n",
    "        self.portfolio_values.append({\n",
    "            \"timestamp\": timestamp,\n",
    "            \"value\": portfolio_value,\n",
    "            \"price\": price\n",
    "        })\n",
    "    \n",
    "    def get_performance_metrics(self):\n",
    "        \"\"\"Calculate performance metrics\"\"\"\n",
    "        if not self.portfolio_values:\n",
    "            return {}\n",
    "            \n",
    "        values = [pv[\"value\"] for pv in self.portfolio_values]\n",
    "        returns = np.diff(values) / values[:-1]\n",
    "        \n",
    "        total_return = (values[-1] / self.initial_capital) - 1\n",
    "        sharpe_ratio = np.mean(returns) / (np.std(returns) + 1e-9) * np.sqrt(252 * 24 * 60)  # Annualized\n",
    "        max_drawdown = self._calculate_max_drawdown(values)\n",
    "        \n",
    "        return {\n",
    "            \"total_return\": total_return,\n",
    "            \"final_capital\": values[-1],\n",
    "            \"sharpe_ratio\": sharpe_ratio,\n",
    "            \"max_drawdown\": max_drawdown,\n",
    "            \"num_trades\": len(self.trades),\n",
    "            \"win_rate\": self._calculate_win_rate()\n",
    "        }\n",
    "    \n",
    "    def _calculate_max_drawdown(self, values):\n",
    "        \"\"\"Calculate maximum drawdown\"\"\"\n",
    "        peak = values[0]\n",
    "        max_dd = 0\n",
    "        for value in values:\n",
    "            if value > peak:\n",
    "                peak = value\n",
    "            dd = (peak - value) / peak\n",
    "            if dd > max_dd:\n",
    "                max_dd = dd\n",
    "        return max_dd\n",
    "    \n",
    "    def _calculate_win_rate(self):\n",
    "        \"\"\"Calculate win rate\"\"\"\n",
    "        if len(self.trades) < 2:\n",
    "            return 0\n",
    "        wins = sum(1 for i in range(1, len(self.trades)) \n",
    "                  if self.trades[i][\"capital\"] > self.trades[i-1][\"capital\"])\n",
    "        return wins / (len(self.trades) - 1)\n",
    "\n",
    "# Quick backtest function\n",
    "async def run_backtest(system: TrendPredictionSystem, backtester: Backtester):\n",
    "    \"\"\"Run backtest on system predictions\"\"\"\n",
    "    \n",
    "    print(\"Running backtest on prediction history...\")\n",
    "    \n",
    "    for pred in system.prediction_history:\n",
    "        timestamp = pred[\"timestamp\"]\n",
    "        price = pred[\"price\"]\n",
    "        signal = pred[\"prediction\"]\n",
    "        confidence = max(pred[\"probabilities\"].values())\n",
    "        \n",
    "        backtester.execute_signal(timestamp, price, signal, confidence)\n",
    "    \n",
    "    # Calculate performance\n",
    "    performance = backtester.get_performance_metrics()\n",
    "    \n",
    "    print(f\"\\n=== BACKTEST RESULTS ===\")\n",
    "    print(f\"Total Return: {performance.get('total_return', 0):.2%}\")\n",
    "    print(f\"Final Capital: ${performance.get('final_capital', 0):.2f}\")\n",
    "    print(f\"Sharpe Ratio: {performance.get('sharpe_ratio', 0):.2f}\")\n",
    "    print(f\"Max Drawdown: {performance.get('max_drawdown', 0):.2%}\")\n",
    "    print(f\"Number of Trades: {performance.get('num_trades', 0)}\")\n",
    "    print(f\"Win Rate: {performance.get('win_rate', 0):.2%}\")\n",
    "    \n",
    "    return performance\n",
    "\n",
    "# Test backtesting\n",
    "if 'system' in locals() and system.prediction_history:\n",
    "    backtester = Backtester(initial_capital=10000)\n",
    "    backtest_results = await run_backtest(system, backtester)\n",
    "else:\n",
    "    print(\"Run prediction system first to generate data for backtesting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d113d8",
   "metadata": {},
   "source": [
    "## 11. Risk Management and Position Sizing\n",
    "\n",
    "Implement risk controls and position sizing for safe deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskManager:\n",
    "    \"\"\"Risk management and position sizing\"\"\"\n",
    "    \n",
    "    def __init__(self, max_position_size=0.1, max_daily_loss=0.05, confidence_threshold=0.6):\n",
    "        self.max_position_size = max_position_size  # 10% max position\n",
    "        self.max_daily_loss = max_daily_loss  # 5% max daily loss\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.daily_pnl = 0\n",
    "        self.positions = {}\n",
    "        \n",
    "    def calculate_position_size(self, signal, confidence, volatility, current_capital):\n",
    "        \"\"\"Calculate appropriate position size\"\"\"\n",
    "        # Base size on confidence and volatility\n",
    "        base_size = self.max_position_size * confidence\n",
    "        \n",
    "        # Adjust for volatility (higher vol = smaller position)\n",
    "        vol_adjustment = min(1.0, 0.02 / max(volatility, 0.001))\n",
    "        adjusted_size = base_size * vol_adjustment\n",
    "        \n",
    "        # Check daily loss limit\n",
    "        if abs(self.daily_pnl) >= self.max_daily_loss * current_capital:\n",
    "            return 0  # Stop trading for the day\n",
    "            \n",
    "        return min(adjusted_size, self.max_position_size)\n",
    "    \n",
    "    def should_take_signal(self, signal, confidence, current_time=None):\n",
    "        \"\"\"Determine if signal should be taken\"\"\"\n",
    "        \n",
    "        # Confidence filter\n",
    "        if confidence < self.confidence_threshold:\n",
    "            return False, \"Low confidence\"\n",
    "            \n",
    "        # Daily loss limit\n",
    "        if hasattr(self, 'daily_pnl') and abs(self.daily_pnl) >= 0.05:\n",
    "            return False, \"Daily loss limit reached\"\n",
    "            \n",
    "        # Market hours check (simple version)\n",
    "        if current_time:\n",
    "            hour = current_time.hour\n",
    "            if hour < 9 or hour > 16:  # Outside market hours\n",
    "                return False, \"Outside market hours\"\n",
    "        \n",
    "        return True, \"Signal approved\"\n",
    "\n",
    "# Complete system with risk management\n",
    "class ProductionTradingSystem(TrendPredictionSystem):\n",
    "    \"\"\"Production-ready trading system with risk management\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        super().__init__(config)\n",
    "        self.risk_manager = RiskManager()\n",
    "        self.trading_enabled = False\n",
    "        self.positions = {}\n",
    "        \n",
    "    async def process_tick_with_trading(self, tick_data: Dict):\n",
    "        \"\"\"Process tick with trading logic\"\"\"\n",
    "        await self.process_tick(tick_data)  # Base processing\n",
    "        \n",
    "        if not self.trading_enabled:\n",
    "            return\n",
    "            \n",
    "        # Get latest prediction\n",
    "        if self.prediction_history:\n",
    "            latest_pred = self.prediction_history[-1]\n",
    "            signal = latest_pred[\"prediction\"]\n",
    "            confidence = max(latest_pred[\"probabilities\"].values())\n",
    "            \n",
    "            # Risk check\n",
    "            should_trade, reason = self.risk_manager.should_take_signal(\n",
    "                signal, confidence, tick_data[\"timestamp\"]\n",
    "            )\n",
    "            \n",
    "            if should_trade:\n",
    "                # Calculate position size\n",
    "                volatility = self._estimate_volatility()\n",
    "                position_size = self.risk_manager.calculate_position_size(\n",
    "                    signal, confidence, volatility, 10000  # Example capital\n",
    "                )\n",
    "                \n",
    "                if position_size > 0:\n",
    "                    print(f\"[TRADE] {signal.upper()} signal: size={position_size:.3f}, \"\n",
    "                          f\"confidence={confidence:.3f}, reason='{reason}'\")\n",
    "            else:\n",
    "                print(f\"[SKIP] Signal rejected: {reason}\")\n",
    "    \n",
    "    def _estimate_volatility(self):\n",
    "        \"\"\"Estimate current volatility from recent bars\"\"\"\n",
    "        recent_bars = self.bar_aggregator.get_recent_bars(10)\n",
    "        if len(recent_bars) < 2:\n",
    "            return 0.02  # Default\n",
    "            \n",
    "        returns = []\n",
    "        for i in range(1, len(recent_bars)):\n",
    "            ret = (recent_bars[i][\"close\"] / recent_bars[i-1][\"close\"]) - 1\n",
    "            returns.append(ret)\n",
    "        \n",
    "        return np.std(returns) if returns else 0.02\n",
    "\n",
    "# Demo the complete system\n",
    "print(\"=== COMPLETE TRADING SYSTEM WITH RISK MANAGEMENT ===\")\n",
    "\n",
    "# Create production system\n",
    "prod_config = CONFIG.copy()\n",
    "prod_config[\"MODEL_TYPE\"] = \"logistic\"  # Faster for demo\n",
    "\n",
    "production_system = ProductionTradingSystem(prod_config)\n",
    "\n",
    "# Enable trading for demo\n",
    "production_system.trading_enabled = True\n",
    "\n",
    "print(\"System ready for production deployment!\")\n",
    "print(\"Key features:\")\n",
    "print(\"✓ Real-time tick processing\")\n",
    "print(\"✓ Feature engineering pipeline\") \n",
    "print(\"✓ Online machine learning\")\n",
    "print(\"✓ 5-minute trend predictions\")\n",
    "print(\"✓ Risk management\")\n",
    "print(\"✓ Performance monitoring\")\n",
    "print(\"✓ Backtesting framework\")\n",
    "\n",
    "# Quick demo with a few ticks\n",
    "mock_gen = MockDataGenerator(\"AAPL\", 150.0)\n",
    "print(\"\\nProcessing sample ticks with trading logic...\")\n",
    "\n",
    "for i in range(20):\n",
    "    tick = mock_gen.generate_tick()\n",
    "    await production_system.process_tick_with_trading(tick)\n",
    "\n",
    "print(f\"\\nFinal system stats:\")\n",
    "stats = production_system.get_stats()\n",
    "for key in [\"ticks_processed\", \"predictions_made\", \"labels_created\"]:\n",
    "    print(f\"  {key}: {stats.get(key, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c5280",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook has implemented a complete real-time stock trend prediction system with:\n",
    "\n",
    "### ✅ Core Components\n",
    "- **WebSocket Integration**: Connect to live stock data feeds\n",
    "- **Data Processing**: Tick-to-bar aggregation and feature engineering\n",
    "- **Online Learning**: River-based adaptive models\n",
    "- **Prediction Pipeline**: 5-minute trend classification\n",
    "- **Risk Management**: Position sizing and safety controls\n",
    "- **Performance Monitoring**: Real-time metrics and visualization\n",
    "- **Backtesting**: Strategy evaluation framework\n",
    "\n",
    "### 🚀 Key Features\n",
    "- **Real-time Processing**: Handle streaming tick data\n",
    "- **Adaptive Learning**: Model updates with new data\n",
    "- **Comprehensive Features**: 30+ technical indicators\n",
    "- **Risk Controls**: Daily loss limits, confidence thresholds\n",
    "- **Production Ready**: Error handling and monitoring\n",
    "\n",
    "### 📊 Performance Metrics\n",
    "- Model accuracy tracking\n",
    "- Prediction confidence analysis\n",
    "- Trading simulation with transaction costs\n",
    "- Risk-adjusted returns (Sharpe ratio)\n",
    "- Maximum drawdown monitoring\n",
    "\n",
    "### 🔧 Next Steps for Production\n",
    "\n",
    "1. **Data Provider Integration**: \n",
    "   - Configure real WebSocket feeds (Alpaca, Polygon, IEX)\n",
    "   - Add authentication and reconnection logic\n",
    "\n",
    "2. **Enhanced Features**:\n",
    "   - Order book data (bid/ask spread)\n",
    "   - Multiple timeframe analysis\n",
    "   - Sector/market regime detection\n",
    "\n",
    "3. **Model Improvements**:\n",
    "   - Ensemble methods\n",
    "   - Deep learning models (LSTM/Transformer)\n",
    "   - Feature selection optimization\n",
    "\n",
    "4. **Infrastructure**:\n",
    "   - Database storage for historical data\n",
    "   - API for external access\n",
    "   - Monitoring and alerting system\n",
    "\n",
    "5. **Compliance & Risk**:\n",
    "   - Regulatory compliance checks\n",
    "   - Enhanced risk management\n",
    "   - Audit trails and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final demonstration - run this to see the complete system in action\n",
    "print(\"=== STOCK TREND PREDICTION SYSTEM - FINAL DEMO ===\\n\")\n",
    "\n",
    "# Create a comprehensive demo\n",
    "async def final_demo():\n",
    "    \"\"\"Complete system demonstration\"\"\"\n",
    "    \n",
    "    print(\"🚀 Starting comprehensive system demo...\")\n",
    "    \n",
    "    # 1. Initialize system\n",
    "    demo_config = {\n",
    "        \"SYMBOL\": \"AAPL\",\n",
    "        \"PRED_HORIZON_MINUTES\": 5,\n",
    "        \"FEATURE_WINDOW_MINUTES\": 15,\n",
    "        \"LABEL_THRESHOLD\": 0.001,\n",
    "        \"MODEL_TYPE\": \"random_forest\",\n",
    "        \"N_ESTIMATORS\": 5,\n",
    "        \"BAR_SECONDS\": 60,\n",
    "    }\n",
    "    \n",
    "    system = TrendPredictionSystem(demo_config)\n",
    "    backtester = Backtester(initial_capital=10000)\n",
    "    \n",
    "    print(\"✅ System initialized\")\n",
    "    \n",
    "    # 2. Generate realistic market data\n",
    "    mock_gen = MockDataGenerator(\"AAPL\", 150.0, volatility=0.025)\n",
    "    \n",
    "    print(\"📊 Processing market data...\")\n",
    "    \n",
    "    # Process more data for better demonstration\n",
    "    for i in range(500):\n",
    "        tick = mock_gen.generate_tick()\n",
    "        await system.process_tick(tick)\n",
    "        \n",
    "        # Add some backtesting\n",
    "        if system.prediction_history and len(system.prediction_history) > 10:\n",
    "            latest = system.prediction_history[-1]\n",
    "            backtester.execute_signal(\n",
    "                latest[\"timestamp\"], \n",
    "                latest[\"price\"], \n",
    "                latest[\"prediction\"],\n",
    "                max(latest[\"probabilities\"].values())\n",
    "            )\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"  Processed {i+1}/500 ticks...\")\n",
    "    \n",
    "    print(\"✅ Data processing complete\")\n",
    "    \n",
    "    # 3. Final results\n",
    "    stats = system.get_stats()\n",
    "    performance = backtester.get_performance_metrics()\n",
    "    \n",
    "    print(\"\\n📈 FINAL RESULTS:\")\n",
    "    print(f\"  • Ticks Processed: {stats['ticks_processed']:,}\")\n",
    "    print(f\"  • Predictions Made: {stats['predictions_made']:,}\")\n",
    "    print(f\"  • Model Accuracy: {stats.get('accuracy', 0):.2%}\")\n",
    "    print(f\"  • Trading Return: {performance.get('total_return', 0):.2%}\")\n",
    "    print(f\"  • Sharpe Ratio: {performance.get('sharpe_ratio', 0):.2f}\")\n",
    "    \n",
    "    # 4. Show recent predictions\n",
    "    print(\"\\n🎯 RECENT PREDICTIONS:\")\n",
    "    recent = system.prediction_history[-5:] if system.prediction_history else []\n",
    "    for pred in recent:\n",
    "        ts = pred['timestamp'].strftime('%H:%M:%S')\n",
    "        price = pred['price']\n",
    "        signal = pred['prediction']\n",
    "        conf = max(pred['probabilities'].values())\n",
    "        print(f\"  {ts}: ${price:.2f} → {signal.upper()} ({conf:.1%})\")\n",
    "    \n",
    "    print(\"\\n🎉 Demo complete! System is ready for production deployment.\")\n",
    "    \n",
    "    return system\n",
    "\n",
    "# Run the final demo\n",
    "demo_system = await final_demo()\n",
    "\n",
    "print(f\"\\n💡 To use this system with real data:\")\n",
    "print(f\"   1. Set up WebSocket provider credentials\")\n",
    "print(f\"   2. Configure the provider in WebSocketConfig\")\n",
    "print(f\"   3. Replace MockDataGenerator with real WebSocket feed\")\n",
    "print(f\"   4. Deploy with proper monitoring and risk controls\")\n",
    "\n",
    "print(f\"\\n⚠️  IMPORTANT DISCLAIMER:\")\n",
    "print(f\"   This is for educational/research purposes only.\")\n",
    "print(f\"   Always backtest thoroughly before live trading.\")\n",
    "print(f\"   Past performance does not guarantee future results.\")\n",
    "print(f\"   Consider regulatory requirements and risk management.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
